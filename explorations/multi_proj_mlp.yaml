# multi_proj_mlp.yaml
---
# Base hyperparameters
max_iters: [3500]
n_layer: [6]
n_head: [6]
n_embd: [384]
block_size: [256]
device: ["cuda"]
dtype: ["bfloat16"]
dataset: ["shakespeare_char"]

# MLP variations to test
mlp_variant:
  - mlp
  - swiglu

# Number of down projections to test
n_down_projs:
  range:
    start: 1
    end: 4
    step: 1

# Learning rate variations
learning_rate: [1e-3, 3e-3]
min_lr: [1e-4]

# Optimizer settings
optimizer: ["adamw"]
weight_decay: [0.1]
grad_clip: [1.0]

# Training settings
batch_size: [64]
dropout: [0.0, 0.1]

# Compile and device settings
compile: [true]
use_gradient_checkpointing: [false]

# Logging settings
eval_interval: [250]
log_interval: [10]
tensorboard_log: [true]
tensorboard_run_name: ["multi_proj_mlp_study"]

# Positional embeddings
use_rotary_embeddings: [true]
use_abs_pos_embeddings: [true]

# Activation and normalization
activation_variant: ["gelu"]
norm_variant_attn: ["rmsnorm"]
norm_variant_output: ["rmsnorm"]

# Random seeds for reproducibility
seed:
  range:
    start: 1337
    end: 1339
    step: 1 