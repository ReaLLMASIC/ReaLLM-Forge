# LLM Japanese Dataset

This folder contains script compatible with the "llm japanese dataset".

More details below.

## Overview
The LLM Japanese Dataset is designed for constructing and tuning Large Language
Models (LLMs) with a focus on Japanese language chat or instruction-response
tasks. This dataset can be particularly useful for adapting models initially
trained in English or other languages to understand and generate Japanese
language responses, using techniques such as LoRA (Low-Rank Adaptation).

## Dataset Details
For detailed information about the dataset, please refer to the following papers:
- Japanese version: [Link to JXIV paper](https://jxiv.jst.go.jp/index.php/jxiv/preprint/view/383)
- English version: [Link to arXiv paper](https://arxiv.org/abs/2305.12720)
- GitHub Repository: [Link to GitHub](https://github.com/masanorihirano/llm-japanese-dataset)
- Latest Information: [llm.msuzuki.me](https://llm.msuzuki.me)
- HuggingFace Page: [llm-japanese-dataset](https://huggingface.co/datasets/izumi-lab/llm-japanese-dataset)

## Citation
If you use this dataset, please cite using the following:

```bibtex
@preprint{Hirano2023-llmj,
  title={{llm-japanese-dataset v0: Construction of Japanese Chat Dataset for Large Language Models and its Methodology}},
  autor={Masanori HIRANO and Masahiro SUZUKI and Hiroki SAKAJI},
  doi={10.48550/arXiv.2305.12720},
  archivePrefix={arXiv},
  arxivId={2305.12720},
  year={2023}
}
```

## Collaboration, Data Provision, and Inquiries
For joint research, data provision, support, and other inquiries about the
dataset, the following contact was provided on the huggingface page: izumi-llm@socsim.org

## License
Versions are available on Github releases, a larger CC-BY-SA 4.0 and a smaller
MIT Licensed release as zip files.
